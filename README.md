# GenAI Security Research Project

## Overview

This repository contains proof-of-concept code for GenAI security research, including Large Language Model (LLM) security research and Multi-agent Chat Protocol (MCP) security experiments. The codebase demonstrates various security vulnerabilities, attack vectors, and defense mechanisms related to AI systems.


## Resources & References

- [PINT Benchmark](https://github.com/lakeraai/pint-benchmark) - Benchmark for testing LLM security vulnerabilities
- [Who is Gandalf?](https://www.lakera.ai/blog/who-is-gandalf) - Lakera's analysis of the Gandalf LLM security challenge
- [Security Research](https://github.com/harishsg993010) - Additional security research resources

## Security Notice
⚠️ IMPORTANT: This code is for educational and research purposes only. Some implementations demonstrate security vulnerabilities and should not be used in production environments without proper safeguards.